{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SQLContext\n",
    "#from pyspark.conf import SparkConf\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.appName(\"Python Spark SQL basic example\").getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark 100M example\")\\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.cores.max\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\",\"4g\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.7.4.jar\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download this file from kaggel it is around 1.4GB non compressed\n",
    "## url: https://www.kaggle.com/datasets/rohanrao/riiid-train-data-multiple-formats?select=riiid_train.parquet \n",
    "\n",
    "path = 'C:/Users/piyus/Downloads/riiid_train/riiid_train.parquet'\n",
    "\n",
    "df_spark = spark.read.option(\"header\",\"true\").option(\"recursiveFileLookup\",\"true\").parquet(path)\n",
    "\n",
    "df_spark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Both Works   #print(df_spark.schema)\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will only show unique id's \n",
    "#df_spark.select('user_id').distinct().show()\n",
    "\n",
    "## This will show id and count\n",
    "#Use this only on small DF\n",
    "#df_spark.groupby('user_id').count().show(n=df_spark.count(), truncate = False)\n",
    "\n",
    "df_spark.groupby('user_id').count().show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
